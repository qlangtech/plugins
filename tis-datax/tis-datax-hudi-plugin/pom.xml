<?xml version="1.0" encoding="UTF-8"?>
<!--~
  ~   Licensed to the Apache Software Foundation (ASF) under one
  ~   or more contributor license agreements.  See the NOTICE file
  ~   distributed with this work for additional information
  ~   regarding copyright ownership.  The ASF licenses this file
  ~   to you under the Apache License, Version 2.0 (the
  ~   "License"); you may not use this file except in compliance
  ~   with the License.  You may obtain a copy of the License at
  ~
  ~       http://www.apache.org/licenses/LICENSE-2.0
  ~
  ~   Unless required by applicable law or agreed to in writing, software
  ~   distributed under the License is distributed on an "AS IS" BASIS,
  ~   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  ~   See the License for the specific language governing permissions and
  ~   limitations under the License.
  -->

<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <parent>
        <groupId>com.qlangtech.tis.plugins</groupId>
        <artifactId>tis-datax</artifactId>
        <version>3.5.0</version>
        <relativePath>../pom.xml</relativePath>
    </parent>
    <!--    <parent>-->
    <!--        <groupId>com.qlangtech.tis.plugins</groupId>-->
    <!--        <artifactId>tis-hive-flat-table-builder-plugin</artifactId>-->
    <!--        <version>3.5.0</version>-->
    <!--        <relativePath>../tis-hive-flat-table-builder-plugin/pom.xml</relativePath>-->
    <!--    </parent>-->


    <modelVersion>4.0.0</modelVersion>

    <artifactId>tis-datax-hudi-plugin</artifactId>
    <packaging>tpi</packaging>
    <properties>
        <spark2.version>2.4.4</spark2.version>
        <spark.dist.dir.name>spark-${spark2.version}-bin-hadoop2.7</spark.dist.dir.name>
        <spark.package.name>${spark.dist.dir.name}.tgz</spark.package.name>

    </properties>
    <build>
        <resources>
            <resource>
                <directory>src/main/resources</directory>
                <filtering>true</filtering>
            </resource>
        </resources>


    </build>

    <dependencies>

        <!--        <dependency>-->
        <!--            <groupId>javax.servlet</groupId>-->
        <!--            <artifactId>javax.servlet-api</artifactId>-->
        <!--            <version>3.1.0</version>-->
        <!--        </dependency>-->

        <dependency>
            <groupId>com.qlangtech.tis.plugins</groupId>
            <artifactId>tis-datax-common-rdbms-plugin</artifactId>
        </dependency>

        <dependency>
            <groupId>com.qlangtech.tis.plugins</groupId>
            <artifactId>tis-datax-hudi-dependency</artifactId>
            <version>${project.version}</version>
            <scope>test</scope>
        </dependency>


        <dependency>
            <groupId>com.qlangtech.tis.plugins</groupId>
            <artifactId>tis-datax-common-plugin</artifactId>
        </dependency>

        <dependency>
            <groupId>com.qlangtech.tis.plugins</groupId>
            <artifactId>tis-datax-hdfs-plugin</artifactId>
        </dependency>

<!--        <dependency>-->
<!--            <groupId>com.qlangtech.tis</groupId>-->
<!--            <artifactId>tis-dag</artifactId>-->
<!--        </dependency>-->
        <dependency>
            <groupId>com.qlangtech.tis.plugins</groupId>
            <artifactId>tis-datax-test-common</artifactId>
            <exclusions>
                <exclusion>
                    <groupId>com.qlangtech.tis</groupId>
                    <artifactId>tis-hadoop-rpc</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>io.netty</groupId>
                    <artifactId>netty</artifactId>
                </exclusion>
            </exclusions>
        </dependency>

        <dependency>
            <groupId>com.qlangtech.tis</groupId>
            <artifactId>tis-common</artifactId>
            <scope>provided</scope>
        </dependency>


        <dependency>
            <groupId>io.netty</groupId>
            <artifactId>netty-all</artifactId>
            <version>4.1.17.Final</version>
        </dependency>

<!--        <dependency>-->
<!--            <groupId>org.apache.spark</groupId>-->
<!--            <artifactId>spark-sql_${scala.binary.version}</artifactId>-->
<!--            <version>${spark2.version}</version>-->
<!--        </dependency>-->

        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-launcher_${scala.binary.version}</artifactId>
            <version>${spark2.version}</version>
        </dependency>



        <dependency>
            <groupId>com.fasterxml.jackson.dataformat</groupId>
            <artifactId>jackson-dataformat-csv</artifactId>
            <version>2.6.7</version>
        </dependency>

<!--        <dependency>-->
<!--            <groupId>com.alibaba.datax</groupId>-->
<!--            <artifactId>hdfswriter</artifactId>-->
<!--            <version>${alibaba.datax.version}</version>-->
<!--            <exclusions>-->
<!--                <exclusion>-->
<!--                    <groupId>com.alibaba.datax</groupId>-->
<!--                    <artifactId>datax-common</artifactId>-->
<!--                </exclusion>-->
<!--                <exclusion>-->
<!--                    <groupId>com.alibaba.datax</groupId>-->
<!--                    <artifactId>plugin-unstructured-storage-util</artifactId>-->
<!--                </exclusion>-->
<!--                <exclusion>-->
<!--                    <groupId>org.apache.hive</groupId>-->
<!--                    <artifactId>hive-serde</artifactId>-->
<!--                </exclusion>-->
<!--                <exclusion>-->
<!--                    <groupId>org.apache.hive</groupId>-->
<!--                    <artifactId>hive-service</artifactId>-->
<!--                </exclusion>-->
<!--                <exclusion>-->
<!--                    <groupId>org.apache.hive</groupId>-->
<!--                    <artifactId>hive-common</artifactId>-->
<!--                </exclusion>-->
<!--                <exclusion>-->
<!--                    <groupId>org.apache.hive.hcatalog</groupId>-->
<!--                    <artifactId>hive-hcatalog-core</artifactId>-->
<!--                </exclusion>-->
<!--            </exclusions>-->
<!--        </dependency>-->


    </dependencies>
    <profiles>
        <profile>
            <id>release</id>
            <activation>
                <property>
                    <name>appname</name>
                    <value>all</value>
                </property>
            </activation>
            <build>
                <plugins>

                    <plugin>
                        <groupId>org.apache.maven.plugins</groupId>
                        <artifactId>maven-antrun-plugin</artifactId>
                        <executions>
                            <execution>
                                <phase>prepare-package</phase>
                                <!--https://ant.apache.org/manual/index.html-->
                                <configuration>
                                    <target>
                                        <untar src="${project.basedir}/../tis-datax-hudi-dependency/tis-datax-hudi-dependency.tar.gz"
                                               dest="${project.build.directory}/${project.build.finalName}"
                                               overwrite="true"
                                               compression="gzip"/>
                                        <mkdir dir="/tmp/tis"/>
                                        <get src="${tis.release.repository.host}/${spark.package.name}"
                                             dest="/tmp/tis/${spark.package.name}" skipexisting="true"
                                             ignoreerrors="false"/>
                                        <untar src="/tmp/tis/${spark.package.name}"
                                               dest="${project.build.directory}/${project.build.finalName}"
                                               overwrite="true"
                                               compression="gzip"/>
<!--                                        <chmod dir="${project.build.directory}/${project.build.finalName}/${spark.dist.dir.name}/bin" perm="ugo+rx"-->
<!--                                               includes="**/*"/>-->
                                    </target>
                                </configuration>
                                <goals>
                                    <goal>run</goal>
                                </goals>
                            </execution>
                        </executions>
                    </plugin>
                </plugins>
            </build>
        </profile>
    </profiles>


</project>
